{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,precision_recall_curve,auc,roc_auc_score,\\\n",
    "roc_curve,recall_score,classification_report ,f1_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"train_submissions.csv\")\n",
    "test_df=pd.read_csv(\"test_submissions.csv\")\n",
    "problem_data_df=pd.read_csv(\"problem_data.csv\")\n",
    "user_data_df=pd.read_csv(\"user_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_tags(df):\n",
    "    df['tags'].fillna(\"UNKNOWN\",inplace=True)\n",
    "    df['tags_test'] = df['tags'].apply(lambda x: [str(i) for i in x.split(',')])\n",
    "    tag_list = df[\"tags_test\"].tolist()\n",
    "    \n",
    "    merged = list(itertools.chain(*tag_list))\n",
    "    unique_tags_list=list(set(merged))\n",
    "    \n",
    "    for i in range(len(unique_tags_list)):\n",
    "        df[unique_tags_list[i]+\"_tag\"]=0\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        for j in range(len(row[\"tags_test\"])):\n",
    "            df.loc[index, row[\"tags_test\"][j]+\"_tag\"] = 1\n",
    "            \n",
    "    df.drop([\"tags_test\"],inplace=True,axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_data_df=encode_tags(problem_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Level_type \"I\",\"J\",\"K\",\"L\",\"M\",\"N\" have always points=none, Therefore, I assume these level_types have points=0 always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_data_df['points'] = np.where(~problem_data_df['level_type'].isin(['I','J','K','L','M','N']), problem_data_df['points'], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rest level_type where points is equal to None, are replaced with mean value of level_types' average points value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_data_df['points'] = problem_data_df.groupby(['level_type'])['points'].apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values in level_type columns is filled with another category \"unknown\" and points corresponding those rows are filled with 0 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_data_df['level_type'].fillna('unknown',inplace=True)\n",
    "problem_data_df['points'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6544, 41)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_df['conversion_rate']=user_data_df['problem_solved']/user_data_df['submission_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_df['last_online_time_date'] = pd.to_datetime(user_data_df['last_online_time_seconds'],unit='s')\n",
    "user_data_df['registration_time_date'] = pd.to_datetime(user_data_df['registration_time_seconds'],unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_df['days_active']=round((user_data_df['last_online_time_seconds']-user_data_df['registration_time_seconds'])/(60*60*24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_df['country'].fillna('unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3571, 15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhbhan/.conda/envs/newron_clone/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train_df['source']='train'\n",
    "test_df['source']='test'\n",
    "full_df=pd.concat([train_df,test_df])\n",
    "full_df=pd.merge(full_df,user_data_df,on=['user_id'])\n",
    "full_df=pd.merge(full_df,problem_data_df,on=['problem_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    \n",
    "    y=df[df['source']=='train']['attempts_range']\n",
    "    df_encode=pd.get_dummies(df[df['source']=='train'][['level_type','rank']])\n",
    "    \n",
    "    X=pd.concat((df[df['source']=='train'].drop([\"source\",\"ID\",'rank','level_type','attempts_range','country','user_id','problem_id','last_online_time_seconds','registration_time_seconds','last_online_time_date','registration_time_date','tags'],axis=1),df_encode),axis=1)\n",
    "    \n",
    "    X_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size=0.3 ,random_state=0)\n",
    "    \n",
    "    df_encode=pd.get_dummies(df[df['source']=='test'][['level_type','rank']])\n",
    "    df_scaled_test=pd.concat((df[df['source']=='test'].drop([\"source\",\"ID\",'rank','level_type','country','user_id','problem_id','last_online_time_seconds','registration_time_seconds','last_online_time_date','registration_time_date','tags'],axis=1),df_encode),axis=1)\n",
    "    \n",
    "    print(f\"Shape of train feature data is: {X_train.shape}\")\n",
    "    print(f\"Shape of train target data is: {y_train.shape}\")\n",
    "    print(f\"Shape of valid feature data is: {X_valid.shape}\")\n",
    "    print(f\"Shape of valid target data is: {y_valid.shape}\")\n",
    "    print(f\"Shape of test data is: {df_scaled_test.shape}\")\n",
    "          \n",
    "    return X_train,X_valid,y_train,y_valid, df_scaled_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train feature data is: (108706, 65)\n",
      "Shape of train target data is: (108706,)\n",
      "Shape of valid feature data is: (46589, 65)\n",
      "Shape of valid target data is: (46589,)\n",
      "Shape of test data is: (66555, 66)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_valid,y_train,y_valid, df_scaled_test=prepare_data(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RadomsearchCV(X,y,model,param_grid,cv,n_jobs=1):\n",
    "    \n",
    "    gs = RandomizedSearchCV(estimator=model, param_distributions=param_grid, scoring='f1_weighted', cv=cv, verbose=2,n_jobs =-1)\n",
    "    gs = gs.fit(X.values,y.values.ravel())\n",
    "    \n",
    "    return gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100,150,200,300,400],\n",
    "    'bootstrap': [True, False],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_depth': [7,8,9,10]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  50 | elapsed:  1.8min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed:  1.9min remaining:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.9min finished\n"
     ]
    }
   ],
   "source": [
    "params=RadomsearchCV(X_train,y_train,RandomForestClassifier(),param_grid,5,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(**params)\n",
    "#model.set_params(**params)\n",
    "model.fit(X_train,y_train)\n",
    "Prediction=model.predict(X_valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________ \n",
      "\n",
      "The accuracy of the XGB Regression is 0.5366717465496147\n",
      "____________________________________________________________________________________________________ \n",
      "\n",
      "The F1 score of the XGB Regression is 0.39384513199576315\n",
      "____________________________________________________________________________________________________ \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.54      0.98      0.70     24868\n",
      "         2.0       0.35      0.04      0.07     14091\n",
      "         3.0       0.00      0.00      0.00      4331\n",
      "         4.0       0.00      0.00      0.00      1619\n",
      "         5.0       0.00      0.00      0.00       750\n",
      "         6.0       0.00      0.00      0.00       930\n",
      "\n",
      "   micro avg       0.54      0.54      0.54     46589\n",
      "   macro avg       0.15      0.17      0.13     46589\n",
      "weighted avg       0.40      0.54      0.39     46589\n",
      "\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhbhan/.conda/envs/newron_clone/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/bhbhan/.conda/envs/newron_clone/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"__\"*50,\"\\n\")\n",
    "print('The accuracy of the XGB Regression is',metrics.accuracy_score(y_valid,Prediction))\n",
    "print(\"__\"*50,\"\\n\")\n",
    "print('The F1 score of the XGB Regression is',metrics.f1_score(y_valid,Prediction,average='weighted'))\n",
    "print(\"__\"*50,\"\\n\")\n",
    "print(classification_report(y_valid,Prediction))\n",
    "print(\"__\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "param_grid = {\n",
    "        'n_estimators': [150,200,300],\n",
    "        'min_child_weight': [3,4],\n",
    "        'gamma':  [0],\n",
    "        'subsample': [ 0.7, 0.8],\n",
    "        'colsample_bytree': [ 0.7, 0.8],\n",
    "        'max_depth': [7,8],\n",
    "        'learning_rate' : [ 0.05, 0.1]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  50 | elapsed:  8.3min remaining: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  50 | elapsed: 13.8min remaining:   53.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 14.2min finished\n"
     ]
    }
   ],
   "source": [
    "params=RadomsearchCV(X_train,y_train,XGBClassifier(),param_grid,5,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(**params)\n",
    "#model.set_params(**params)\n",
    "model.fit(X_train,y_train)\n",
    "Prediction=model.predict(X_valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________ \n",
      "\n",
      "The accuracy of the XGB Regression is 0.5413509626735925\n",
      "____________________________________________________________________________________________________ \n",
      "\n",
      "The F1 score of the XGB Regression is 0.4573480004884017\n",
      "____________________________________________________________________________________________________ \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.58      0.90      0.70     24868\n",
      "         2.0       0.37      0.20      0.26     14091\n",
      "         3.0       0.23      0.01      0.01      4331\n",
      "         4.0       0.25      0.00      0.01      1619\n",
      "         5.0       0.25      0.00      0.01       750\n",
      "         6.0       0.31      0.02      0.05       930\n",
      "\n",
      "   micro avg       0.54      0.54      0.54     46589\n",
      "   macro avg       0.33      0.19      0.17     46589\n",
      "weighted avg       0.46      0.54      0.46     46589\n",
      "\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"__\"*50,\"\\n\")\n",
    "print('The accuracy of the XGB Regression is',metrics.accuracy_score(y_valid,Prediction))\n",
    "print(\"__\"*50,\"\\n\")\n",
    "print('The F1 score of the XGB Regression is',metrics.f1_score(y_valid,Prediction,average='weighted'))\n",
    "print(\"__\"*50,\"\\n\")\n",
    "print(classification_report(y_valid,Prediction))\n",
    "print(\"__\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['attempts_range']=model.predict(df_scaled_test.drop('attempts_range',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['ID','attempts_range']].to_csv(\"XGBoost_tuned_Submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
